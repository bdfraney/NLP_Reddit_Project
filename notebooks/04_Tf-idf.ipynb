{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Term Frequency - Inverse Document Frequency Vectorization\n",
    "---\n",
    "\n",
    "Comparing CountVectorizer with Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df= pd.read_csv('../data/reddit_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>locked</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Previous](/r/AskHistorians/search?q=title%3A\"...</td>\n",
       "      <td>Sunday Digest | Interesting &amp;amp; Overlooked P...</td>\n",
       "      <td>2019-07-07 14:04:52</td>\n",
       "      <td>Sunday Digest | Interesting &amp;amp; Overlooked P...</td>\n",
       "      <td>sunday digest interesting amp overlooked post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Previous weeks!](/r/AskHistorians/search?sort...</td>\n",
       "      <td>Short Answers to Simple Questions | July 10, 2019</td>\n",
       "      <td>2019-07-10 14:05:16</td>\n",
       "      <td>Short Answers to Simple Questions | July 10, 2...</td>\n",
       "      <td>short answer simple question july 10 2019 prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tiikerinsilma</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>I'm asking this partially because the atrociti...</td>\n",
       "      <td>(WW2) Did Japan have genocidal plans for Asia,...</td>\n",
       "      <td>2019-07-10 09:09:07</td>\n",
       "      <td>(WW2) Did Japan have genocidal plans for Asia,...</td>\n",
       "      <td>ww2 japan genocidal plan asia war asking parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr_Quinn</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In 1627 the last aurochs, or wild cow, died in...</td>\n",
       "      <td>2019-07-10 14:00:39</td>\n",
       "      <td>In 1627 the last aurochs, or wild cow, died in...</td>\n",
       "      <td>1627 last aurochs wild cow died jaktor w fores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Erezen</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Moreover, how was the movie received in South ...</td>\n",
       "      <td>\"The Gods Must Be Crazy\" is a beloved South Af...</td>\n",
       "      <td>2019-07-09 20:36:09</td>\n",
       "      <td>\"The Gods Must Be Crazy\" is a beloved South Af...</td>\n",
       "      <td>god must crazy beloved south african movie rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit         author  locked  num_comments  \\\n",
       "0          1  AutoModerator       0            84   \n",
       "1          1  AutoModerator       0             1   \n",
       "2          1  tiikerinsilma       0            26   \n",
       "3          1       Mr_Quinn       0            10   \n",
       "4          1         Erezen       0            14   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  [Previous](/r/AskHistorians/search?q=title%3A\"...   \n",
       "1  [Previous weeks!](/r/AskHistorians/search?sort...   \n",
       "2  I'm asking this partially because the atrociti...   \n",
       "3                                                NaN   \n",
       "4  Moreover, how was the movie received in South ...   \n",
       "\n",
       "                                               title            timestamp  \\\n",
       "0  Sunday Digest | Interesting &amp; Overlooked P...  2019-07-07 14:04:52   \n",
       "1  Short Answers to Simple Questions | July 10, 2019  2019-07-10 14:05:16   \n",
       "2  (WW2) Did Japan have genocidal plans for Asia,...  2019-07-10 09:09:07   \n",
       "3  In 1627 the last aurochs, or wild cow, died in...  2019-07-10 14:00:39   \n",
       "4  \"The Gods Must Be Crazy\" is a beloved South Af...  2019-07-09 20:36:09   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Sunday Digest | Interesting &amp; Overlooked P...   \n",
       "1  Short Answers to Simple Questions | July 10, 2...   \n",
       "2  (WW2) Did Japan have genocidal plans for Asia,...   \n",
       "3  In 1627 the last aurochs, or wild cow, died in...   \n",
       "4  \"The Gods Must Be Crazy\" is a beloved South Af...   \n",
       "\n",
       "                                     full_text_clean  \n",
       "0  sunday digest interesting amp overlooked post ...  \n",
       "1  short answer simple question july 10 2019 prev...  \n",
       "2  ww2 japan genocidal plan asia war asking parti...  \n",
       "3  1627 last aurochs wild cow died jaktor w fores...  \n",
       "4  god must crazy beloved south african movie rel...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with only text and tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= reddit_df['full_text_clean']\n",
    "y= reddit_df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, stratify=y, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi = TfidfVectorizer(ngram_range=(1,2), # Keep n_gram range consistent with cvec\n",
    "                     max_df=.98,\n",
    "                     min_df=2)\n",
    "\n",
    "X_train_tfi = tfi.fit_transform(X_train) \n",
    "X_test_tfi = tfi.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_tfi.toarray(), columns = tfi.get_feature_names())\n",
    "X_test_df = pd.DataFrame(X_test_tfi.toarray(), columns = tfi.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flake\\Anaconda3\\envs\\GA_DSI\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9749498997995992"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_df, y_train)\n",
    "lr.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667334669338678"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Accuracy** = $0.975$\n",
    "\n",
    "**Test Accuracy** = $0.867$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_tfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specificity and Sensitivity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.92\n",
      "Sensitivity: 0.82\n"
     ]
    }
   ],
   "source": [
    "print(f'Specificity: {round(tn / (fp + tn), 2)}')\n",
    "\n",
    "print(f'Sensitivity: {round(tp /(tp + fn), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(f1_score(y_test, y_pred),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Val Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8750540540540539"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train_tfi, y_train, cv=20, n_jobs=4).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The tf-idf did significantly worse than the Countvectorizer.  My assumption would be that frequency in each document has a neglible effect because each post has a very specific event and time period and it would be the topic of the post as a whole (i.e. American Revolution/Civil War or Ancient Rome) rather than a weighted average of individual terms. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
