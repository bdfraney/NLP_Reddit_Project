{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pre-processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_df = pd.read_csv('../data/ask_historians.csv')\n",
    "hist_df = pd.read_csv('../data/history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Removing Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df= pd.concat([ask_df, hist_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit       0.000000\n",
       "author          0.000000\n",
       "locked          0.000000\n",
       "num_comments    0.000000\n",
       "selftext        0.182866\n",
       "title           0.000000\n",
       "timestamp       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaNs are justs with no selftext so no reason to drop and better to fill with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column that includes the full text of the post; both the body and title for a self.text posts.\n",
    "\n",
    "reddit_df['full_text']= reddit_df.eval('title + selftext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit       0\n",
       "author          0\n",
       "locked          0\n",
       "num_comments    0\n",
       "selftext        0\n",
       "title           0\n",
       "timestamp       0\n",
       "full_text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit       object\n",
       "author          object\n",
       "locked           int64\n",
       "num_comments     int64\n",
       "selftext        object\n",
       "title           object\n",
       "timestamp       object\n",
       "full_text       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from class code, cleans and lemmatizes the text.\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "def lem_str(text):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Remove non-letters and trailing \\n + some number.\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    text = text.replace(r'[\\\\\\n0-9]', ' ')\n",
    "    \n",
    "    # Convert to lower case, split/tokenize into individual words.\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    lem = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
    "    \n",
    "    return\" \".join(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['full_text_clean']= reddit_df['full_text'].map(lem_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3992, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.70390781563126"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_of_posts= np.array([len(post.split()) for post in reddit_df['full_text_clean']])\n",
    "lengths_of_posts.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average length of posts across all subreddits:** $47.7$ words per post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining my postive and negative class.  AskHistorians is positive and History is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['subreddit']= reddit_df['subreddit'].map({'AskHistorians': 1,\n",
    "                           'history': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>locked</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>[Previous](/r/AskHistorians/search?q=title%3A\"...</td>\n",
       "      <td>Sunday Digest | Interesting &amp;amp; Overlooked P...</td>\n",
       "      <td>2019-07-07 14:04:52</td>\n",
       "      <td>Sunday Digest | Interesting &amp;amp; Overlooked P...</td>\n",
       "      <td>sunday digest interesting amp overlooked post ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Previous weeks!](/r/AskHistorians/search?sort...</td>\n",
       "      <td>Short Answers to Simple Questions | July 10, 2019</td>\n",
       "      <td>2019-07-10 14:05:16</td>\n",
       "      <td>Short Answers to Simple Questions | July 10, 2...</td>\n",
       "      <td>short answer simple question july 10 2019 prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tiikerinsilma</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>I'm asking this partially because the atrociti...</td>\n",
       "      <td>(WW2) Did Japan have genocidal plans for Asia,...</td>\n",
       "      <td>2019-07-10 09:09:07</td>\n",
       "      <td>(WW2) Did Japan have genocidal plans for Asia,...</td>\n",
       "      <td>ww2 japan genocidal plan asia war asking parti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr_Quinn</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>In 1627 the last aurochs, or wild cow, died in...</td>\n",
       "      <td>2019-07-10 14:00:39</td>\n",
       "      <td>In 1627 the last aurochs, or wild cow, died in...</td>\n",
       "      <td>1627 last aurochs wild cow died jaktor w fores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Erezen</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Moreover, how was the movie received in South ...</td>\n",
       "      <td>\"The Gods Must Be Crazy\" is a beloved South Af...</td>\n",
       "      <td>2019-07-09 20:36:09</td>\n",
       "      <td>\"The Gods Must Be Crazy\" is a beloved South Af...</td>\n",
       "      <td>god must crazy beloved south african movie rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit         author  locked  num_comments  \\\n",
       "0          1  AutoModerator       0            84   \n",
       "1          1  AutoModerator       0             1   \n",
       "2          1  tiikerinsilma       0            26   \n",
       "3          1       Mr_Quinn       0            10   \n",
       "4          1         Erezen       0            14   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  [Previous](/r/AskHistorians/search?q=title%3A\"...   \n",
       "1  [Previous weeks!](/r/AskHistorians/search?sort...   \n",
       "2  I'm asking this partially because the atrociti...   \n",
       "3                                                      \n",
       "4  Moreover, how was the movie received in South ...   \n",
       "\n",
       "                                               title            timestamp  \\\n",
       "0  Sunday Digest | Interesting &amp; Overlooked P...  2019-07-07 14:04:52   \n",
       "1  Short Answers to Simple Questions | July 10, 2019  2019-07-10 14:05:16   \n",
       "2  (WW2) Did Japan have genocidal plans for Asia,...  2019-07-10 09:09:07   \n",
       "3  In 1627 the last aurochs, or wild cow, died in...  2019-07-10 14:00:39   \n",
       "4  \"The Gods Must Be Crazy\" is a beloved South Af...  2019-07-09 20:36:09   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Sunday Digest | Interesting &amp; Overlooked P...   \n",
       "1  Short Answers to Simple Questions | July 10, 2...   \n",
       "2  (WW2) Did Japan have genocidal plans for Asia,...   \n",
       "3  In 1627 the last aurochs, or wild cow, died in...   \n",
       "4  \"The Gods Must Be Crazy\" is a beloved South Af...   \n",
       "\n",
       "                                     full_text_clean  \n",
       "0  sunday digest interesting amp overlooked post ...  \n",
       "1  short answer simple question july 10 2019 prev...  \n",
       "2  ww2 japan genocidal plan asia war asking parti...  \n",
       "3  1627 last aurochs wild cow died jaktor w fores...  \n",
       "4  god must crazy beloved south african movie rel...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1996\n",
       "0    1996\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.to_csv('../data/reddit_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
